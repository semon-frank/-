"""
V9_auto_adaptive_stable_fixed.py
--------------------------------
ç‰ˆæœ¬ï¼šV9 ç¨³å®šä¿®æ­£ç‰ˆï¼ˆå…¼å®¹æ—§ç‰ˆ sklearnï¼Œæ—  squared å‚æ•°ï¼‰
è‡ªåŠ¨è‡ªé€‚åº”æ™ºèƒ½å»ºæ¨¡è„šæœ¬ã€‚
"""

import os
import argparse
import pandas as pd
import numpy as np
from math import sqrt
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.impute import KNNImputer, SimpleImputer
import lightgbm as lgb
import joblib
import warnings

warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)


def impute_data(df, method="knn"):
    """æ•°æ®å¡«è¡¥å‡½æ•°"""
    numeric_df = df.select_dtypes(include=[np.number])
    if method == "knn":
        print(f"ğŸ”§ ä½¿ç”¨ KNN å¡«è¡¥ ({numeric_df.shape[1]} åˆ—)...")
        imputer = KNNImputer(n_neighbors=5)
        imputed = imputer.fit_transform(numeric_df)
    elif method == "mean":
        print(f"ğŸ”§ ä½¿ç”¨å‡å€¼å¡«è¡¥ ({numeric_df.shape[1]} åˆ—)...")
        imputer = SimpleImputer(strategy="mean")
        imputed = imputer.fit_transform(numeric_df)
    elif method == "ffill_bfill":
        print("ğŸ”§ ä½¿ç”¨å‰åå€¼å¡«è¡¥...")
        return df.ffill().bfill()
    else:
        raise ValueError(f"æœªçŸ¥å¡«è¡¥æ–¹æ³•: {method}")
    df[numeric_df.columns] = imputed
    return df


def build_and_train(df, target_col, outdir, random_state=42):
    """æ„å»ºå¹¶è®­ç»ƒæ¨¡å‹"""
    print(f"ğŸ¯ æ­£åœ¨è®­ç»ƒç›®æ ‡: {target_col}")
    feature_cols = [c for c in df.columns if c != target_col and pd.api.types.is_numeric_dtype(df[c])]
    df_train = df.dropna(subset=[target_col])
    if len(df_train) < 10:
        print(f"âš ï¸ è·³è¿‡ {target_col}, æ ·æœ¬å¤ªå°‘ ({len(df_train)})")
        return None

    X = df_train[feature_cols]
    y = df_train[target_col]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)

    model = lgb.LGBMRegressor(
        n_estimators=500,
        learning_rate=0.05,
        max_depth=-1,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=random_state,
    )

    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    r2 = r2_score(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    rmse = sqrt(mean_squared_error(y_test, y_pred))  # âœ… ä¿®å¤å…¼å®¹
    print(f"âœ… {target_col}: RÂ²={r2:.3f}, MAE={mae:.3f}, RMSE={rmse:.3f}")

    # ä¿å­˜æ¨¡å‹
    os.makedirs(outdir, exist_ok=True)
    model_path = os.path.join(outdir, f"model_{target_col}.joblib")
    joblib.dump(model, model_path)
    print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {model_path}")
    return {"target": target_col, "r2": r2, "mae": mae, "rmse": rmse}


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--input", required=True)
    parser.add_argument("--outdir", required=True)
    parser.add_argument("--resample", type=int, default=10)
    parser.add_argument("--impute", choices=["knn", "ffill_bfill", "mean"], default="knn")
    parser.add_argument("--lag_hours", type=int, default=3)
    parser.add_argument("--max_rows", type=int, default=20000)
    parser.add_argument("--time_budget", type=int, default=600)
    parser.add_argument("--subsample_frac", type=float, default=1.0)
    parser.add_argument("--random_state", type=int, default=42)
    args = parser.parse_args()

    print(f"ğŸ“‚ åŠ è½½æ•°æ®: {args.input}")
    df = pd.read_csv(args.input, low_memory=False)
    print(f"âœ… åŸå§‹æ ·æœ¬æ•°: {len(df)}")

    # æ—¶é—´åˆ—å¤„ç†
    time_cols = [c for c in df.columns if "time" in c.lower()]
    if time_cols:
        df[time_cols[0]] = pd.to_datetime(df[time_cols[0]], errors="coerce")
        df = df.set_index(time_cols[0]).sort_index()
        print(f"ğŸ•’ ä½¿ç”¨æ—¶é—´åˆ—: {time_cols[0]}")
    else:
        raise ValueError("æœªæ‰¾åˆ°æ—¶é—´åˆ—ã€‚")

    # personality_mean
    behavior_cols = [c for c in df.columns if "behavior_" in c.lower()]
    if len(behavior_cols) > 0:
        print(f"ğŸ§  è®¡ç®— personality_meanï¼Œä½¿ç”¨ {len(behavior_cols)} ä¸ªè¡Œä¸ºåˆ—ã€‚")
        df[behavior_cols] = df[behavior_cols].apply(pd.to_numeric, errors="coerce")
        df["personality_mean"] = df[behavior_cols].mean(axis=1)
    else:
        df["personality_mean"] = np.nan
        print("âš ï¸ æœªå‘ç°è¡Œä¸ºåˆ—ï¼Œpersonality_mean å¡« NaNã€‚")

    # é‡é‡‡æ ·
    df = df.resample(f"{args.resample}T").mean(numeric_only=True)
    print(f"âœ… æˆåŠŸé‡é‡‡æ ·ä¸º {args.resample} åˆ†é’Ÿé—´éš”ï¼Œå…± {len(df)} æ¡è®°å½•ã€‚")

    # æ»åç‰¹å¾
    for h in range(1, args.lag_hours + 1):
        for col in df.columns:
            if pd.api.types.is_numeric_dtype(df[col]):
                df[f"{col}_lag{h}h"] = df[col].shift(h)
    print(f"ğŸ” å·²ç”Ÿæˆæ»åç‰¹å¾ (1~{args.lag_hours} å°æ—¶)ã€‚")

    # å¡«è¡¥ç¼ºå¤±å€¼
    df = impute_data(df, method=args.impute)

    # é™åˆ¶è¡Œæ•°
    if len(df) > args.max_rows:
        df = df.tail(args.max_rows)
        print(f"ğŸ“ é™åˆ¶æœ€å¤§è¡Œæ•°ä¸º {args.max_rows}")

    # ç¡®å®šç›®æ ‡åˆ—
    target_candidates = [c for c in df.columns if any(x in c.lower() for x in ["stress", "mood", "pam", "sleep"])]
    print(f"ğŸ¯ è®­ç»ƒç›®æ ‡: {target_candidates}")

    results = []
    for t in target_candidates:
        res = build_and_train(df, t, args.outdir, random_state=args.random_state)
        if res:
            results.append(res)

    print("\nâœ… æ™ºèƒ½å»ºæ¨¡ V9 è‡ªé€‚åº”ç¨³å®šç‰ˆ å®Œæˆ ğŸš€")
    summary_path = os.path.join(args.outdir, "summary_results.csv")
    pd.DataFrame(results).to_csv(summary_path, index=False)
    print(f"ğŸ“Š æ±‡æ€»ç»“æœå·²ä¿å­˜: {summary_path}")


if __name__ == "__main__":
    main()
